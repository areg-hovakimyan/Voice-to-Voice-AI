{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VoiceRecorder import VoiceRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = VoiceRecorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording to voice3.wav...\n",
      "Silence detected. Stopping...\n",
      "Audio saved as voice3.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'voice3.wav'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.start_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (choose 'tiny', 'base', 'small', 'medium', 'large-v2' depending on your hardware)\n",
    "model_size = \"base\"\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")  # Use \"cpu\" if MPS is not supported\n",
    "\n",
    "# Transcribe an audio file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"voices/voice3.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s - 7.00s]:  What is the easiest way to leave the jail in Monopoly?\n"
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(f\"[{segment.start:.2f}s - {segment.end:.2f}s]: {segment.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large-v3\", download_root=\"~/.cache/whisper\").to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_path = \"/opt/homebrew/bin\"  # For Apple Silicon (M1/M2)\n",
    "# ffmpeg_path = \"/usr/local/bin\"  # Uncomment this if using an Intel Mac\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/areghovakimyan/Desktop/Voice-to-Voice-AI/venv/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe('voices/voice4.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Hey, how are you doing?',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 18.0,\n",
       "   'text': ' Hey, how are you doing?',\n",
       "   'tokens': [50365, 1911, 11, 577, 366, 291, 884, 30, 51265],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.537682580947876,\n",
       "   'compression_ratio': 0.7419354838709677,\n",
       "   'no_speech_prob': 0.13029277324676514}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████▏                    | 1.26G/2.88G [16:08<20:45, 1.39MiB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Model has been downloaded but the SHA256 checksum does not not match. Please retry loading the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Load Whisper model on CPU (since MPS has issues)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlarge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Define audio file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice1.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Voice-to-Voice-AI/venv/lib/python3.10/site-packages/whisper/__init__.py:137\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    134\u001b[0m     download_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXDG_CACHE_HOME\u001b[39m\u001b[38;5;124m\"\u001b[39m, default), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[0;32m--> 137\u001b[0m     checkpoint_file \u001b[38;5;241m=\u001b[39m \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     alignment_heads \u001b[38;5;241m=\u001b[39m _ALIGNMENT_HEADS[name]\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(name):\n",
      "File \u001b[0;32m~/Desktop/Voice-to-Voice-AI/venv/lib/python3.10/site-packages/whisper/__init__.py:91\u001b[0m, in \u001b[0;36m_download\u001b[0;34m(url, root, in_memory)\u001b[0m\n\u001b[1;32m     89\u001b[0m model_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(download_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hashlib\u001b[38;5;241m.\u001b[39msha256(model_bytes)\u001b[38;5;241m.\u001b[39mhexdigest() \u001b[38;5;241m!=\u001b[39m expected_sha256:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel has been downloaded but the SHA256 checksum does not not match. Please retry loading the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_bytes \u001b[38;5;28;01mif\u001b[39;00m in_memory \u001b[38;5;28;01melse\u001b[39;00m download_target\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Model has been downloaded but the SHA256 checksum does not not match. Please retry loading the model."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import ssl\n",
    "import whisper\n",
    "import certifi\n",
    "\n",
    "# Ensure SSL certificates are correctly set\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context  # TEMPORARY: Ignores SSL errors\n",
    "\n",
    "# Ensure FFmpeg is accessible (Homebrew path for M1/M2 Macs)\n",
    "ffmpeg_path = \"/opt/homebrew/bin\"  # For Apple Silicon (M1/M2)\n",
    "# ffmpeg_path = \"/usr/local/bin\"  # Uncomment this if using an Intel Mac\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_path\n",
    "\n",
    "# Load Whisper model on CPU (since MPS has issues)\n",
    "device = \"cpu\"\n",
    "model = whisper.load_model(\"large\").to(device)\n",
    "\n",
    "# Define audio file\n",
    "audio_file = \"voice1.wav\"\n",
    "\n",
    "# Check if the file exists before transcribing\n",
    "if os.path.exists(audio_file):\n",
    "    result = model.transcribe(audio_file, language=\"hy\")  # Set Armenian language\n",
    "    print(\"Transcription (Armenian):\", result[\"text\"])\n",
    "else:\n",
    "    print(f\"Error: File '{audio_file}' not found. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
